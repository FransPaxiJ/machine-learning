{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139634ab",
   "metadata": {},
   "source": [
    "# Verificar el RUC de la empresa en la SUNAT usando Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37393be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e366030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto del segundo h4: 20601725551 - CLINICA CERRO COLORADO S.A.C.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument('--headless')  # Descomenta para modo sin interfaz gráfica\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Inicializar el driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Navegar a una página\n",
    "    driver.get('https://e-consultaruc.sunat.gob.pe/cl-ti-itmrconsruc/FrameCriterioBusquedaWeb.jsp')\n",
    "    \n",
    "    # Esperar y encontrar el input usando su ID\n",
    "    input_field = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"txtRuc\"]'))\n",
    "    )\n",
    "\n",
    "    # Esperar un momento para asegurarse de que la página esté lista\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Escribir en el input\n",
    "    input_field.send_keys(\"20601725551\")\n",
    "\n",
    "    # hacer click en boton de buscar\n",
    "    boton_buscar = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"btnAceptar\"]'))\n",
    "    )\n",
    "    boton_buscar.click()\n",
    "    \n",
    "    # Esperar para ver los resultados\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Obtener todos los h4 dentro de div.list-group\n",
    "    elementos_h4 = driver.find_elements(By.CSS_SELECTOR, \"div.list-group h4\")\n",
    "    \n",
    "    # Obtener el segundo h4 (índice 1)\n",
    "    if len(elementos_h4) >= 2:\n",
    "        texto_elemento = elementos_h4[1]\n",
    "        print(\"Texto del segundo h4:\", texto_elemento.text)\n",
    "    else:\n",
    "        print(\"No hay suficientes elementos h4\")\n",
    "\n",
    "        \n",
    "finally:\n",
    "    # Cerrar el navegador\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f129209",
   "metadata": {},
   "source": [
    "# Verificar el DNI de una persona en la RENIEC usando Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46968bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos extraídos: JORDY JOSEPH LOAYZA GIRALT\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# Configurar opciones de Chrome\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument('--headless')  # Descomenta para modo sin interfaz gráfica\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "\n",
    "# Inicializar el driver\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Navegar a una página\n",
    "    driver.get('https://eldni.com/')\n",
    "    \n",
    "    # Esperar y encontrar el input del DNI\n",
    "    input_dni = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"dni\"]'))\n",
    "    )\n",
    "    \n",
    "    # Esperar un momento\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Escribir el DNI\n",
    "    input_dni.send_keys(\"78887022\")\n",
    "    \n",
    "    # Hacer click en el botón de buscar\n",
    "    boton_buscar = WebDriverWait(driver, 10).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, '//*[@id=\"btn-buscar-datos-por-dni\"]'))\n",
    "    )\n",
    "    boton_buscar.click()\n",
    "    \n",
    "    # Esperar para ver los resultados\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Extraer el texto del elemento samp\n",
    "    texto_resultado = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"column-center\"]/div[1]/div[1]/samp'))\n",
    "    )\n",
    "    \n",
    "    print(\"Datos extraídos:\", texto_resultado.text)\n",
    "         \n",
    "finally:\n",
    "    # Cerrar el navegador\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18d3009",
   "metadata": {},
   "source": [
    "# (DESCARTADO) Verificar el NOMBRE del COMPROBANTE con un modelo de inteligencia artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96bf5f2",
   "metadata": {},
   "source": [
    "## Probar un NOMBRE y Apellidos con NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a856032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: CONDORI QUISPICHITO MIGUEL ANGEL, confianza: 85%\n",
      "text: INVERSIONES RUBIN'S S.A.C, confianza: 0%\n",
      "text: 41979614, confianza: 0%\n",
      "text: BOLETA DE VENTA, confianza: 0%\n",
      "text: PAXI JUCHANI FRANS EDWARD, confianza: 46%\n",
      "text: GARCIA LOPEZ JUAN CARLOS, confianza: 83%\n",
      "text: 20427799973, confianza: 0%\n",
      "text: MAMANI MAMANI GIAN GROBER, confianza: 0%\n",
      "text: TOTAL A PAGAR, confianza: 0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class NameDetection:\n",
    "    \"\"\"Información de un nombre detectado\"\"\"\n",
    "    text: str\n",
    "    confidence: float\n",
    "\n",
    "class NERModelConfig:\n",
    "    \"\"\"Configuración del modelo NER\"\"\"\n",
    "    MODEL_NAME = \"MMG/xlm-roberta-large-ner-spanish\"\n",
    "    BATCH_SIZE = 8\n",
    "    CONFIDENCE_THRESHOLD = 0.0  # ✨ Cambiado a 0.0 para capturar TODO\n",
    "\n",
    "\n",
    "class DeviceSelector:\n",
    "    \"\"\"Selecciona el mejor dispositivo disponible\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_best_device() -> torch.device:\n",
    "        \"\"\"Retorna el mejor dispositivo disponible (MPS > CUDA > CPU)\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "class NERModelLoader:\n",
    "    \"\"\"Responsable de cargar y configurar el modelo NER\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, device: torch.device):\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        self.pipeline = self._load_model()\n",
    "    \n",
    "    def _load_model(self) -> pipeline:\n",
    "        \"\"\"Carga el modelo con optimizaciones\"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        model = AutoModelForTokenClassification.from_pretrained(\n",
    "            self.model_name,\n",
    "            torch_dtype=torch.float16 if self.device.type != \"cpu\" else torch.float32\n",
    "        )\n",
    "        \n",
    "        model = model.to(self.device)\n",
    "        model.eval()\n",
    "        \n",
    "        return pipeline(\n",
    "            \"ner\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            aggregation_strategy=\"simple\",\n",
    "            device=self.device,\n",
    "            batch_size=NERModelConfig.BATCH_SIZE\n",
    "        )\n",
    "\n",
    "\n",
    "class TextFilter:\n",
    "    \"\"\"Filtra textos que obviamente no son nombres\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_valid_candidate(texto: str) -> bool:\n",
    "        \"\"\"Verifica si un texto es candidato válido para ser nombre\"\"\"\n",
    "        if any(char.isdigit() for char in texto):\n",
    "            return False\n",
    "        \n",
    "        palabras = texto.split()\n",
    "        if len(palabras) < 2:\n",
    "            return False\n",
    "        \n",
    "        if any(len(p) < 2 or len(p) > 20 for p in palabras):\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "\n",
    "class PersonNameClassifier:\n",
    "    \"\"\"Clasifica si un texto es un nombre de persona\"\"\"\n",
    "    \n",
    "    def __init__(self, ner_pipeline: pipeline, confidence_threshold: float = NERModelConfig.CONFIDENCE_THRESHOLD):\n",
    "        self.ner_pipeline = ner_pipeline\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.text_filter = TextFilter()\n",
    "    \n",
    "    def classify_batch(self, textos: List[str]) -> List[NameDetection]:\n",
    "        \"\"\"Clasifica múltiples textos y retorna TODOS con su confianza\"\"\"\n",
    "        resultados = []\n",
    "        textos_validos = []\n",
    "        indices_originales = []\n",
    "        \n",
    "        # Separar textos válidos de inválidos\n",
    "        for i, texto in enumerate(textos):\n",
    "            if self.text_filter.is_valid_candidate(texto):\n",
    "                textos_validos.append(texto)\n",
    "                indices_originales.append(i)\n",
    "            else:\n",
    "                # Texto inválido (tiene números, muy corto, etc.)\n",
    "                resultados.append(NameDetection(\n",
    "                    text=texto,\n",
    "                    confidence=0.0\n",
    "                ))\n",
    "        \n",
    "        if not textos_validos:\n",
    "            return resultados\n",
    "        \n",
    "        # Procesar con NER los textos válidos\n",
    "        with torch.no_grad():\n",
    "            entidades_batch = self.ner_pipeline(textos_validos)\n",
    "        \n",
    "        # Crear lista temporal con resultados de textos válidos\n",
    "        resultados_validos = []\n",
    "        for idx, entidades in enumerate(entidades_batch):\n",
    "            detection = self._get_person_entity_with_confidence(\n",
    "                entidades,\n",
    "                textos_validos[idx]\n",
    "            )\n",
    "            resultados_validos.append(detection)\n",
    "        \n",
    "        # Reconstruir orden original\n",
    "        resultado_final = []\n",
    "        idx_validos = 0\n",
    "        for i, texto in enumerate(textos):\n",
    "            if self.text_filter.is_valid_candidate(texto):\n",
    "                resultado_final.append(resultados_validos[idx_validos])\n",
    "                idx_validos += 1\n",
    "            else:\n",
    "                resultado_final.append(NameDetection(text=texto, confidence=0.0))\n",
    "        \n",
    "        return resultado_final\n",
    "    \n",
    "    def _get_person_entity_with_confidence(\n",
    "        self, \n",
    "        entidades: List, \n",
    "        texto_original: str\n",
    "    ) -> NameDetection:\n",
    "        \"\"\"Extrae la confianza de la entidad (siempre retorna NameDetection)\"\"\"\n",
    "        max_confidence = 0.0\n",
    "        \n",
    "        for ent in entidades:\n",
    "            if ent['entity_group'] == \"PER\":\n",
    "                max_confidence = max(max_confidence, ent['score'])\n",
    "        \n",
    "        return NameDetection(\n",
    "            text=texto_original,\n",
    "            confidence=max_confidence\n",
    "        )\n",
    "\n",
    "\n",
    "class ResultPrinter:\n",
    "    \"\"\"Responsable de imprimir resultados\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_results(detections: List[NameDetection]):\n",
    "        \"\"\"Imprime TODOS los textos con su confianza\"\"\"\n",
    "        for detection in detections:\n",
    "            confidence_percent = detection.confidence * 100\n",
    "            print(f\"text: {detection.text}, confianza: {confidence_percent:.0f}%\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Datos de prueba\n",
    "    ocr_texts = [\n",
    "        \"CONDORI QUISPICHITO MIGUEL ANGEL\",\n",
    "        \"INVERSIONES RUBIN'S S.A.C\",\n",
    "        \"41979614\",\n",
    "        \"BOLETA DE VENTA\",\n",
    "        \"PAXI JUCHANI FRANS EDWARD\",\n",
    "        \"GARCIA LOPEZ JUAN CARLOS\",\n",
    "        \"20427799973\",\n",
    "        \"MAMANI MAMANI GIAN GROBER\",\n",
    "        \"TOTAL A PAGAR\",\n",
    "    ]\n",
    "    \n",
    "    # Configurar dispositivo\n",
    "    device = DeviceSelector.get_best_device()\n",
    "    \n",
    "    # Cargar modelo\n",
    "    model_loader = NERModelLoader(NERModelConfig.MODEL_NAME, device)\n",
    "    \n",
    "    # Crear clasificador\n",
    "    classifier = PersonNameClassifier(model_loader.pipeline)\n",
    "    \n",
    "    # Clasificar textos\n",
    "    detections = classifier.classify_batch(ocr_texts)\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    ResultPrinter.print_results(detections)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09b8452",
   "metadata": {},
   "source": [
    "## Probar con un COMPROBANTE con NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4822bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicializando EasyOCR...\n",
      "Cargando modelo NER en mps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️  Cargando imagen: WhatsApp Image 2025-10-16 at 21.24.34.jpeg\n",
      "\n",
      "--- Procesando imagen ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/torch2/lib/python3.10/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textos detectados: 91\n",
      "Tiempo de inferencia: 1.90s\n",
      "\n",
      "Clasificando 91 textos con NER...\n",
      "\n",
      "==================================================\n",
      "=== RESULTADOS CLASIFICACIÓN NER ===\n",
      "=== (Ordenados de Mayor a Menor Confianza) ===\n",
      "==================================================\n",
      "1. Texto: Mifarnag8\", Confianza: 0.00%\n",
      "2. Texto: NiFARhA S,A €, Confianza: 0.00%\n",
      "3. Texto: RUC: 20512002090, Confianza: 0.00%\n",
      "4. Texto: CENTRAL:, Confianza: 0.00%\n",
      "5. Texto: Cal ., Confianza: 0.00%\n",
      "6. Texto: Victor, Confianza: 0.00%\n",
      "7. Texto: Alzamor a, Confianza: 68.87%\n",
      "8. Texto: Tro, Confianza: 0.00%\n",
      "9. Texto: T77, Confianza: 0.00%\n",
      "10. Texto: Urb, Confianza: 0.00%\n",
      "11. Texto: Santa, Confianza: 0.00%\n",
      "12. Texto: Catalina, Confianza: 90.41%\n",
      "13. Texto: La Victoria, Confianza: 0.00%\n",
      "14. Texto: Lima TELF, Confianza: 0.00%\n",
      "15. Texto: 2130760, Confianza: 0.00%\n",
      "16. Texto: Tienoa €55, Confianza: 0.00%\n",
      "17. Texto: JULIAcA SaN RoHAN 3, Confianza: 0.00%\n",
      "18. Texto: 1052, Confianza: 0.00%\n",
      "19. Texto: Jr, Confianza: 0.00%\n",
      "20. Texto: San Roman Nro, 521 Puno, Confianza: 0.00%\n",
      "21. Texto: San Ronan, Confianza: 0.00%\n",
      "22. Texto: Juhiaca, Confianza: 0.00%\n",
      "23. Texto: Boleta de venta electronica Bc55-00408563, Confianza: 0.00%\n",
      "24. Texto: Fecha EhISIoN:  10/09/2025 12:47:02, Confianza: 0.00%\n",
      "25. Texto: NHP : 0001062881, Confianza: 0.00%\n",
      "26. Texto: CaJA/TURNO; 51/1, Confianza: 0.00%\n",
      "27. Texto: CAJERO: NOxx#Pe, Confianza: 81.50%\n",
      "28. Texto: CodiGo, Confianza: 0.00%\n",
      "29. Texto: deSCRIPCion, Confianza: 0.00%\n",
      "30. Texto: CANT, Confianza: 0.00%\n",
      "31. Texto: P.Unit., Confianza: 0.00%\n",
      "32. Texto: DSCTO ., Confianza: 0.00%\n",
      "33. Texto: [HPORTE, Confianza: 0.00%\n",
      "34. Texto: 571264, Confianza: 0.00%\n",
      "35. Texto: Rimofluihucil SoL NASAL Fco 1o HL, Confianza: 99.38%\n",
      "36. Texto: LUKOLL Etico, Confianza: 0.00%\n",
      "37. Texto: 47,800, Confianza: 0.00%\n",
      "38. Texto: 47.82, Confianza: 0.00%\n",
      "39. Texto: 528910, Confianza: 0.00%\n",
      "40. Texto: Palcosil   goohg  pvo sobre, Confianza: 82.02%\n",
      "41. Texto: HKT   phARMA  NAC, Confianza: 0.00%\n",
      "42. Texto: 5, Confianza: 0.00%\n",
      "43. Texto: 2.800, Confianza: 0.00%\n",
      "44. Texto: 14.00, Confianza: 0.00%\n",
      "45. Texto: 302830, Confianza: 0.00%\n",
      "46. Texto: hezyh 5hG tableta ReCuBiERta, Confianza: 0.00%\n",
      "47. Texto: HKT phARHA NAC, Confianza: 0.00%\n",
      "48. Texto: 15, Confianza: 0.00%\n",
      "49. Texto: 3.300, Confianza: 0.00%\n",
      "50. Texto: 49.50, Confianza: 0.00%\n",
      "51. Texto: OP , GRAvADAS: S/, Confianza: 0.00%\n",
      "52. Texto: 94.32, Confianza: 0.00%\n",
      "53. Texto: IGV-18% ; S/, Confianza: 0.00%\n",
      "54. Texto: 16.97, Confianza: 0.00%\n",
      "55. Texto: ihpoRte Total: 5/, Confianza: 0.00%\n",
      "56. Texto: 211.30, Confianza: 0.00%\n",
      "57. Texto: SoN, Confianza: 0.00%\n",
      "58. Texto: ciento ohce CoN 30/100 SOLES, Confianza: 0.00%\n",
      "59. Texto: EFECTIVO SOLES, Confianza: 0.00%\n",
      "60. Texto: 112.00, Confianza: 0.00%\n",
      "61. Texto: VUELTO: s/, Confianza: 0.00%\n",
      "62. Texto: 0.70, Confianza: 0.00%\n",
      "63. Texto: Guarda tu voucher. Es e1, Confianza: 0.00%\n",
      "64. Texto: sustento para validar, Confianza: 0.00%\n",
      "65. Texto: tu compra, Confianza: 0.00%\n",
      "66. Texto: Representacion, Confianza: 0.00%\n",
      "67. Texto: mpresa de Ia BOLETA DE VENTA ELECTRONICA, Confianza: 0.00%\n",
      "68. Texto: puede, Confianza: 0.00%\n",
      "69. Texto: ser  consultado en, Confianza: 0.00%\n",
      "70. Texto: cpe. mifarma col . pe, Confianza: 0.00%\n",
      "71. Texto: Autoriza, Confianza: 0.00%\n",
      "72. Texto: do Hediante Resolucien Nra, Confianza: 0.00%\n",
      "73. Texto: 0180050001024 /SUNAT, Confianza: 0.00%\n",
      "74. Texto: Cambios, Confianza: 0.00%\n",
      "75. Texto: devoluciones: Salvo 7o dispuesto pur, Confianza: 0.00%\n",
      "76. Texto: Tos art 97, Confianza: 0.00%\n",
      "77. Texto: 98, Confianza: 0.00%\n",
      "78. Texto: demncs  de, Confianza: 0.00%\n",
      "79. Texto: 29571 ,, Confianza: 0.00%\n",
      "80. Texto: ap], Confianza: 0.00%\n",
      "81. Texto: 7o dispuesto en nuestra, Confianza: 0.00%\n",
      "82. Texto: olatica de satisfaccien qarantizada  que podrcs revisar, Confianza: 0.00%\n",
      "83. Texto: n: htips; /uvv_mifarMa_cum_Lelalencion lientes_clausula, Confianza: 0.00%\n",
      "84. Texto: 20], Confianza: 0.00%\n",
      "85. Texto: VVM . mi farma con_pe, Confianza: 0.00%\n",
      "86. Texto: 3,26 0, Confianza: 0.00%\n",
      "87. Texto: USUARIU HuimP, Confianza: 0.00%\n",
      "88. Texto: TAJA: 51, Confianza: 0.00%\n",
      "89. Texto: VRi, Confianza: 0.00%\n",
      "90. Texto: Ley, Confianza: 0.00%\n",
      "91. Texto: icar€, Confianza: 0.00%\n",
      "==================================================\n",
      "\n",
      "🎯 PRIMER NOMBRE CON CONFIANZA > 20%:\n",
      "   Texto: Alzamor a\n",
      "   Confianza: 68.87%\n",
      "\n",
      "⏱️  Tiempo total OCR: 1.90s\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import easyocr\n",
    "import time\n",
    "import numpy as np\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from typing import List, Tuple, Optional, Union\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "@dataclass\n",
    "class NameDetection:\n",
    "    \"\"\"Información de un nombre detectado\"\"\"\n",
    "    text: str\n",
    "    confidence: float\n",
    "\n",
    "class NERModelConfig:\n",
    "    \"\"\"Configuración del modelo NER\"\"\"\n",
    "    MODEL_NAME = \"MMG/xlm-roberta-large-ner-spanish\"\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "class DeviceSelector:\n",
    "    \"\"\"Selecciona el mejor dispositivo disponible\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_best_device() -> torch.device:\n",
    "        \"\"\"Retorna el mejor dispositivo disponible (MPS > CUDA > CPU)\"\"\"\n",
    "        if torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "        elif torch.cuda.is_available():\n",
    "            return torch.device(\"cuda\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "class ImageLoader:\n",
    "    \"\"\"Responsable de cargar imágenes desde PDF o archivos de imagen\"\"\"\n",
    "    \n",
    "    SUPPORTED_FORMATS = {'.pdf', '.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.webp'}\n",
    "    \n",
    "    @classmethod\n",
    "    def load_images(cls, file_path: str, dpi: int = 300) -> List:\n",
    "        \"\"\"Carga imágenes desde PDF o archivos de imagen\"\"\"\n",
    "        file_ext = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        if file_ext not in cls.SUPPORTED_FORMATS:\n",
    "            raise ValueError(f\"Formato no soportado: {file_ext}. Formatos válidos: {cls.SUPPORTED_FORMATS}\")\n",
    "        \n",
    "        if file_ext == '.pdf':\n",
    "            return cls._load_from_pdf(file_path, dpi)\n",
    "        else:\n",
    "            return cls._load_from_image(file_path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_from_pdf(pdf_path: str, dpi: int) -> List:\n",
    "        \"\"\"Convierte un PDF a lista de imágenes\"\"\"\n",
    "        print(f\"📄 Convirtiendo PDF a imágenes (DPI: {dpi})...\")\n",
    "        return convert_from_path(pdf_path, dpi=dpi)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _load_from_image(image_path: str) -> List:\n",
    "        \"\"\"Carga una imagen individual\"\"\"\n",
    "        print(f\"🖼️  Cargando imagen: {os.path.basename(image_path)}\")\n",
    "        imagen = Image.open(image_path)\n",
    "        return [imagen]\n",
    "\n",
    "class OCRProcessor:\n",
    "    \"\"\"Responsable de procesar OCR en imágenes\"\"\"\n",
    "    \n",
    "    def __init__(self, language: str = 'es'):\n",
    "        \"\"\"Inicializa el lector OCR\"\"\"\n",
    "        print(\"Inicializando EasyOCR...\")\n",
    "        self.reader = easyocr.Reader([language])\n",
    "    \n",
    "    def process_images(self, imagenes: List) -> Tuple[List[str], float]:\n",
    "        \"\"\"Procesa todas las imágenes y retorna textos con tiempo total\"\"\"\n",
    "        all_texts = []\n",
    "        total_time = 0\n",
    "        \n",
    "        for i, imagen in enumerate(imagenes):\n",
    "            if len(imagenes) > 1:\n",
    "                print(f'\\n--- Página {i+1}/{len(imagenes)} ---')\n",
    "            else:\n",
    "                print(f'\\n--- Procesando imagen ---')\n",
    "            \n",
    "            # Convertir PIL Image a numpy array\n",
    "            imagen_np = np.array(imagen)\n",
    "            \n",
    "            # Realizar OCR y medir tiempo\n",
    "            start_time = time.time()\n",
    "            resultados = self.reader.readtext(imagen_np)\n",
    "            inference_time = time.time() - start_time\n",
    "            total_time += inference_time\n",
    "            \n",
    "            # Extraer textos detectados\n",
    "            page_texts = []\n",
    "            for bbox, texto, confianza in resultados:\n",
    "                page_texts.append(texto)\n",
    "            \n",
    "            print(f'Textos detectados: {len(page_texts)}')\n",
    "            print(f'Tiempo de inferencia: {inference_time:.2f}s')\n",
    "            all_texts.extend(page_texts)\n",
    "        \n",
    "        return all_texts, total_time\n",
    "\n",
    "class NERModelLoader:\n",
    "    \"\"\"Responsable de cargar y configurar el modelo NER\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, device: torch.device):\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        print(f\"Cargando modelo NER en {device}...\")\n",
    "        self.pipeline = self._load_model()\n",
    "    \n",
    "    def _load_model(self) -> pipeline:\n",
    "        \"\"\"Carga el modelo con optimizaciones\"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        model = AutoModelForTokenClassification.from_pretrained(\n",
    "            self.model_name,\n",
    "            torch_dtype=torch.float16 if self.device.type != \"cpu\" else torch.float32\n",
    "        )\n",
    "        \n",
    "        model = model.to(self.device)\n",
    "        model.eval()\n",
    "        \n",
    "        return pipeline(\n",
    "            \"ner\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            aggregation_strategy=\"simple\",\n",
    "            device=self.device,\n",
    "            batch_size=NERModelConfig.BATCH_SIZE\n",
    "        )\n",
    "\n",
    "class PersonNameClassifier:\n",
    "    \"\"\"Clasifica si un texto es un nombre de persona\"\"\"\n",
    "    \n",
    "    def __init__(self, ner_pipeline: pipeline):\n",
    "        self.ner_pipeline = ner_pipeline\n",
    "    \n",
    "    def classify_batch(self, textos: List[str]) -> List[NameDetection]:\n",
    "        \"\"\"Clasifica TODOS los textos sin filtrado previo\"\"\"\n",
    "        if not textos:\n",
    "            return []\n",
    "        \n",
    "        print(f\"\\nClasificando {len(textos)} textos con NER...\")\n",
    "        \n",
    "        # Procesar todos los textos directamente con NER\n",
    "        with torch.no_grad():\n",
    "            entidades_batch = self.ner_pipeline(textos)\n",
    "        \n",
    "        # Crear lista con resultados\n",
    "        resultados = []\n",
    "        for idx, entidades in enumerate(entidades_batch):\n",
    "            detection = self._get_person_entity_with_confidence(\n",
    "                entidades,\n",
    "                textos[idx]\n",
    "            )\n",
    "            resultados.append(detection)\n",
    "        \n",
    "        return resultados\n",
    "    \n",
    "    def _get_person_entity_with_confidence(\n",
    "        self, \n",
    "        entidades: List, \n",
    "        texto_original: str\n",
    "    ) -> NameDetection:\n",
    "        \"\"\"Extrae la confianza de la entidad PER (siempre retorna NameDetection)\"\"\"\n",
    "        max_confidence = 0.0\n",
    "        \n",
    "        for ent in entidades:\n",
    "            if ent['entity_group'] == \"PER\":\n",
    "                max_confidence = max(max_confidence, ent['score'])\n",
    "        \n",
    "        return NameDetection(\n",
    "            text=texto_original,\n",
    "            confidence=max_confidence\n",
    "        )\n",
    "\n",
    "class ResultPrinter:\n",
    "    \"\"\"Responsable de imprimir resultados\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def print_ner_results(detections: List[NameDetection]):\n",
    "        \"\"\"Imprime resultados de clasificación NER ordenados por confianza\"\"\"\n",
    "        print(f'\\n{\"=\"*50}')\n",
    "        print(f'=== RESULTADOS CLASIFICACIÓN NER ===')\n",
    "        print(f'=== (Ordenados de Mayor a Menor Confianza) ===')\n",
    "        print(f'{\"=\"*50}')\n",
    "        for i, detection in enumerate(detections, 1):\n",
    "            confidence_percent = detection.confidence * 100\n",
    "            print(f\"{i}. Texto: {detection.text}, Confianza: {confidence_percent:.2f}%\")\n",
    "        print(f'{\"=\"*50}')\n",
    "\n",
    "    @staticmethod\n",
    "    def get_first_with_confidence(detections: List[NameDetection], min_confidence: float = 0.20) -> Optional[NameDetection]:\n",
    "        \"\"\"Obtiene el primer texto con confianza mayor al threshold\"\"\"\n",
    "        for detection in detections:\n",
    "            if detection.confidence > min_confidence:\n",
    "                return detection\n",
    "        return None\n",
    "\n",
    "class ComprobanteNameProcessor:\n",
    "    \"\"\"Orquestador principal del procesamiento de nombres en comprobantes\"\"\"\n",
    "    \n",
    "    def __init__(self, file_path: str):\n",
    "        self.file_path = file_path\n",
    "        self.image_loader = ImageLoader()\n",
    "        self.ocr_processor = OCRProcessor()\n",
    "        self.result_printer = ResultPrinter()\n",
    "        \n",
    "        # Configurar dispositivo y cargar modelo NER\n",
    "        device = DeviceSelector.get_best_device()\n",
    "        model_loader = NERModelLoader(NERModelConfig.MODEL_NAME, device)\n",
    "        self.classifier = PersonNameClassifier(model_loader.pipeline)\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"Procesa el archivo completo: Carga + OCR + Clasificación NER\"\"\"\n",
    "        # 1. Cargar imágenes (desde PDF o archivo de imagen)\n",
    "        imagenes = self.image_loader.load_images(self.file_path)\n",
    "        \n",
    "        # 2. Procesar OCR\n",
    "        all_texts, ocr_time = self.ocr_processor.process_images(imagenes)\n",
    "        \n",
    "        # 3. Clasificar nombres con NER\n",
    "        detections = self.classifier.classify_batch(all_texts)\n",
    "        \n",
    "        # 4. Imprimir resultados NER\n",
    "        self.result_printer.print_ner_results(detections)\n",
    "        \n",
    "        # 5. Imprimir el primer nombre con confianza > 20%\n",
    "        primer_nombre = self.result_printer.get_first_with_confidence(detections)\n",
    "        \n",
    "        if primer_nombre:\n",
    "            confidence_percent = primer_nombre.confidence * 100\n",
    "            print(f'\\n🎯 PRIMER NOMBRE CON CONFIANZA > 20%:')\n",
    "            print(f'   Texto: {primer_nombre.text}')\n",
    "            print(f'   Confianza: {confidence_percent:.2f}%')\n",
    "        else:\n",
    "            print('\\n⚠️  No se encontró ningún texto con confianza mayor a 20%')\n",
    "        \n",
    "        print(f'\\n⏱️  Tiempo total OCR: {ocr_time:.2f}s')\n",
    "        \n",
    "        return detections\n",
    "\n",
    "def main():\n",
    "    file_path = 'comprobante/WhatsApp Image 2025-10-16 at 21.24.34.jpeg'\n",
    "    \n",
    "    processor = ComprobanteNameProcessor(file_path)\n",
    "    detections = processor.process()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
